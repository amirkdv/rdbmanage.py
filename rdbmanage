#!/usr/bin/env python
import datetime
import os
import sys
import pwd
import time
import argparse
import traceback
import subprocess
import shlex
from ConfigParser import SafeConfigParser

_debug = True

class Failure(Exception): pass

class Job(object):
    def __init__(self, name, opts):
        self.name = str(name)
        self.opts = dict(opts)

    # the prefered method of failing so they all get logged. Failures raised in
    # this program are assumed to all have initiated here (and hence logged).
    def fail(self, message):
        message = str(message)
        tb = traceback.format_stack()
        if tb:
            tb.pop(-1)
            message += ''.join(tb)
        self.log(message)
        raise Failure(message)

    # defaults to log only to log file, echo=True to write on stderr.
    def log(self, message, echo=False):
        message = '[job: %s] %s' % (self.name, str(message).strip() + '\n')
        if echo or _debug:
            sys.stderr.write(message)
        with open(self.opts['logs'], 'a+') as f:
            f.write('[%s] %s' % (_readable_date(), message))

    # returns the number of revisions fetched (0 or 1). Raises a Failure in case
    # of error.
    def backup(self, force=False):
        incrs = self.incrs()
        latest = incrs[-1] if len(incrs) else -1
        age = int(time.time()) - latest
        max_age = float(self.opts['max_mirror_age']) * 3600
        msg = 'mirror for {0:s} is {1:.2f} hrs old'.format(self.name, age/3600.00)
        msg += ' (max allowed: {0:.2f} hrs)'.format(max_age/3600)
        if age >= max_age or force:
            self.log(msg + ', fetching new revision.\n')
        else:
            self.log(msg + ', nothing to do.\n')
            return 0
        if self.opts['pre_backup_cmd']:
            self.log("pre-backup: %s" % self.opts['pre_backup_cmd'])
            self._subp_cmd(shlex.split(self.opts['pre_backup_cmd']))
        self.log('starting backup: %s' % self.opts['backup_cmd'])
        self._subp_cmd(shlex.split(self.opts['backup_cmd']))
        return 1

    # returns an array of integers, each the Unix timestamp of an increment
    def incrs(self, readable=False):
        path = self.opts['dir']
        if not os.path.exists(os.path.join(path, 'rdiff-backup-data')):
            return []
        out, _ = self._subp_cmd(['rdiff-backup', '-l',
                                 '--parsable-output', path])
        incrs = sorted([int(l.split(' ')[0]) for l in out.strip().split('\n')])
        if readable:
            return [_readable_date(incr) for incr in incrs]
        else:
            return incrs

    # removes old revisions as per conf
    # Failure in case of error.
    def clear(self):
        max_keep = self.opts['max_keep']
        incrs = self.incrs()
        n_incrs = len(incrs)
        msg = '%s has %s revisions (max allowed: %s)' % \
                (self.name, n_incrs, n_incrs)
        if n_incrs <= max_keep:
            self.log(msg + ', nothing to clear.\n')
        else:
            self.log(msg + ', clearing old revisions\n')
            threshold = incrs[n_incrs - max_keep] - 1
            self._subp_cmd(['rdiff-backup', '--remove-older-than',
                           str(threshold), '--force', self.opts['dir']])

    # runs the status_cmd (intended to be light sanity check), raises Failure in
    # case of error.
    def test(self):
        self.log('testing config and connection for %s' % self.name)
        self._subp_cmd(shlex.split(self.opts['status_cmd']))

    # runs a command in a subprocess as the user of this job; returns a tuple of
    # strings for (stdout, stderr) and raises a Failure in case of error.
    #
    # All arguments (except for preexec_fn, stdout, and stderr) are passed
    # untouched to Popen constructor.
    def _subp_cmd(self, args, **kwargs):
        def demote(pwd_record):
            uid = pwd_record.pw_uid
            gid = pwd_record.pw_gid
            def f():
                if os.getuid() == uid: return
                os.setgid(gid)
                os.setuid(uid)
            return f
        try:
            kwargs.update({
                'preexec_fn': demote(pwd.getpwnam(self.opts['user'])),
                'stdout': subprocess.PIPE,
                'stderr': subprocess.PIPE
            })
            proc = subprocess.Popen(args, **kwargs)
        except (OSError, KeyError) as e:
            self.fail(e)
        out, err = proc.communicate()
        if proc.returncode:
            self.fail('===(failure - code: %s)===\n' % proc.returncode +
                      '---(command)---\n%s---\n' % ' '.join(args) +
                      '---(stdout)---\n%s\n---(stderr)---\n%s\n' % (out, err))
        return (out, err)

class RdbManage(object):
    def __init__(self, conf_path):
        self.parser = SafeConfigParser()
        self.parser.read(conf_path)

    def load_job(self, name):
        items = self.parser.items('job:' + name, vars={'job': name})
        opts = {k: v.replace('\n', ' ') for (k,v) in items}
        return Job(name, opts)

    @property
    def jobs(self):
        return [sec[4:] for sec in self.parser.sections() if sec[:4] == 'job:']

    # update a single job, returns 0 for success, 2 for failure
    def update_job(self, name, force=False):
        job = self.load_job(name)
        try:
            job.test()
            job.backup(force=force)
            job.clear()
            return 0
        except Failure:
            sys.stderr.write('Failed to update %s, see logs at %s\n' % \
                                (job.name, job.opts['logs']))
            return 1

    # updates all jobs up to a maximum number of operations; -1 means no maximum
    # returns 0 for success, 2 for failure
    def update_all(self, max_ops=-1):
        fail_cnt = 0
        ops = 0
        for name in self.jobs:
            if max_ops != -1 and ops >= max_ops:
                sys.stderr.write('Hit maximum no. of %s operations, exiting.\n' % max_ops)
                break
            job = self.load_job(name)
            incrs = 0
            try:
                job.test()
                incrs = job.backup()
                if incrs:
                    job.clear()
            except Failure:
                fail_cnt += 1
                sys.stderr.write('Failed to update %s, see logs at %s\n' % \
                                    (job.name, job.opts['logs']))
            if incrs:
                ops += 1
        return fail_cnt


def _readable_date(timestamp=None):
    fmt = "%Y-%m-%dT%H:%M:%S"
    if not timestamp:
        return datetime.datetime.now().strftime(fmt)
    else:
        return datetime.datetime.fromtimestamp(timestamp).strftime()

# returned values are exit codes of rdbmanage:
#   0 success, 1 bad usage, 2 config not found
def main(args):
    parser = argparse.ArgumentParser(prog='rdbmanage')
    parser.add_argument('-c', dest='conf_file', action='store',
                        default=os.path.join(os.getcwd(), 'rdbmanage.conf'),
                        help='string: path to rdbmanage configuration file')
    parser.add_argument('-j', dest='job', action='store',
                        help='string: job to update (backup and clear)')
    parser.add_argument('-m', dest='max_ops', action='store',
                        help="""integer: maximum number of increments to fetch
                                (-1 implies no maximum), -m is ignored if -j
                                is provided.""")
    parser.add_argument('-f', dest='force', action='store_true',
                        help="""flag: force fetch a backup, -f is ignored if
                                -m is provided.""")
    namespace = parser.parse_args(args)
    conf = namespace.conf_file
    if not os.path.exists(conf):
        sys.stderr.write("No such file '{}'\n".format(conf))
        return 2
    M = RdbManage(conf)
    if namespace.job:
        return M.update_job(namespace.job, force=namespace.force)
    elif namespace.max_ops:
        return M.update_all(namespace.max_ops)
    else:
        parser.print_help()
        return 2

if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))
